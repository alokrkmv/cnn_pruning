{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "itertaive_prunning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4480408ae07f453aae0e1d4dd829bfb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4e8f1c9699674a91ad2474c378547a70",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_798f517c239d460ca82132f7e5f7f80a",
              "IPY_MODEL_7266fbe418f3476389903d9912e6db1f",
              "IPY_MODEL_47341fa53abc41f8a296c05a1c65bf7c"
            ]
          }
        },
        "4e8f1c9699674a91ad2474c378547a70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "798f517c239d460ca82132f7e5f7f80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a6c132d8ae9545f489ca4f7cbddc3dc8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea27a4759a124009ad7d72e140b3d877"
          }
        },
        "7266fbe418f3476389903d9912e6db1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_730f0ef2884d46629a3fac102875ea26",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75d6ea5a40c042ba8350f79cc2634d5b"
          }
        },
        "47341fa53abc41f8a296c05a1c65bf7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4d128d3cb6a4965998d496b6334d636",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 57446224.65it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_945e8c79a662469093373c2d091c54ac"
          }
        },
        "a6c132d8ae9545f489ca4f7cbddc3dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea27a4759a124009ad7d72e140b3d877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "730f0ef2884d46629a3fac102875ea26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75d6ea5a40c042ba8350f79cc2634d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4d128d3cb6a4965998d496b6334d636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "945e8c79a662469093373c2d091c54ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg4c-sBXOS2N",
        "outputId": "aa325fa0-3bed-4be3-96d0-24a52133111f"
      },
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ-bYeaTOj0s"
      },
      "source": [
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/cs532/cnn-pruning-status_200-main.zip\")\n",
        "zip_ref.extractall(\"content/tmp\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AkyhnEhPIEL"
      },
      "source": [
        "import torch\n",
        "import copy\n",
        "import torch.nn.utils.prune as prune\n",
        "import math\n",
        "from torchvision import datasets,transforms\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG7h2PF2QPBY",
        "outputId": "2bab2dd0-35c6-4818-dcc4-6c76b9273bf2"
      },
      "source": [
        "%cd content/tmp/cnn-pruning-status_200-main"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/content/tmp/cnn-pruning-status_200-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgMFkc-5PWnf",
        "outputId": "32d755db-f751-4252-cbd4-a799892c85e2"
      },
      "source": [
        "# Load the pretrained model\n",
        "from cifar10_models.resnet import resnet18\n",
        "my_model = resnet18()\n",
        "\n",
        "# Pretrained model\n",
        "my_model = resnet18(pretrained=True)\n",
        "my_model.eval()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frWPMPOiPk8w"
      },
      "source": [
        "#calculate sparsity ratio\n",
        "def calculate_sparsity(model):\n",
        "  total_count = 0\n",
        "  zero_count = 0\n",
        "  \n",
        "  for buffer_name, buffer in model.named_buffers():\n",
        "    zero_count += torch.sum(buffer == 0).item()\n",
        "    if zero_count>0:\n",
        "      total_count += buffer.nelement()\n",
        "\n",
        "  print(\"Total params: \", total_count)\n",
        "  print(\"Zero params: \", zero_count)\n",
        "  return (math.ceil(zero_count*100/total_count))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "4480408ae07f453aae0e1d4dd829bfb4",
            "4e8f1c9699674a91ad2474c378547a70",
            "798f517c239d460ca82132f7e5f7f80a",
            "7266fbe418f3476389903d9912e6db1f",
            "47341fa53abc41f8a296c05a1c65bf7c",
            "a6c132d8ae9545f489ca4f7cbddc3dc8",
            "ea27a4759a124009ad7d72e140b3d877",
            "730f0ef2884d46629a3fac102875ea26",
            "75d6ea5a40c042ba8350f79cc2634d5b",
            "e4d128d3cb6a4965998d496b6334d636",
            "945e8c79a662469093373c2d091c54ac"
          ]
        },
        "id": "qpO49BIDRE3N",
        "outputId": "9ce3bf3c-95a6-4479-9a3b-87a6f3f1ea0f"
      },
      "source": [
        "print(\"Preparing_data ======>\")\n",
        "transform_train = transforms.Compose([\n",
        "                                    transforms.RandomCrop(32,padding=4),\n",
        "                                    transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010))\n",
        "])\n",
        "                                \n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root = './data',train=True,download=True,transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size=128,shuffle=True,num_workers=2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing_data ======>\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4480408ae07f453aae0e1d4dd829bfb4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgPpR8gTRL5q"
      },
      "source": [
        "loss_history = []\n",
        "correct_history = []\n",
        "val_loss_history = []\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpHoMDq6RQf7"
      },
      "source": [
        "def get_optimizer(model):\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.1,momentum=0,weight_decay=5e-4)\n",
        "  return optimizer"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJqoAnSwR8HI"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP7zoKRsRU_X"
      },
      "source": [
        "def train(epoch,model):\n",
        "  model.train()\n",
        "  train_acc = 0\n",
        "  train_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "    inputs,targets = inputs.to(device),targets.to(device)\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs,targets)\n",
        "    optimizer = get_optimizer(model)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    _,predicted = outputs.max(1)\n",
        "    total +=targets.size(0)\n",
        "    correct += predicted.eq(targets).sum().item()\n",
        "    train_acc = 100 *correct/total\n",
        "  if epoch % 5 == 1:\n",
        "    print(\"Training\")\n",
        "    print('[%d/%d] Loss: %.3f | Acc: %.3f (%d/%d)' %(batch_idx,len(trainloader),train_loss/(batch_idx+1),100.*correct/total,correct,total))\n",
        "    print('Current learning rate is: {}'.format(optimizer.param_groups[0]['lr']))\n",
        "  loss_history.append(train_loss)\n",
        "  correct_history.append(train_acc)\n",
        "\n",
        "  return min(loss_history),max(correct_history)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_4x4s3YQ3Jb",
        "outputId": "8659edd4-d90b-4f63-847f-1c1532af8a94"
      },
      "source": [
        "epochs = 11\n",
        "# Build and save the iterative pruning model with 50 % sparsity ratio\n",
        "model1 = copy.deepcopy(my_model)\n",
        "parameters_to_prune =[]\n",
        "for module_name, module in model1.named_modules():\n",
        "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
        "            parameters_to_prune.append((module, \"weight\"))\n",
        "print(\"Layers to prune {}\".format((len(parameters_to_prune))))\n",
        "for i in range(5):\n",
        "  print(f\"Iteration *********************************************** {i+1} **************************************************\" )\n",
        "  prune.global_unstructured(\n",
        "  parameters_to_prune,\n",
        "  pruning_method=prune.L1Unstructured,\n",
        "  amount=0.128,\n",
        "  )\n",
        "  model1= model1.to(device)\n",
        "  for e in range(epochs):\n",
        "    if(e+1)%5==1:\n",
        "      print(f\"Epoch ======> {e+1}\")\n",
        "    train(e+1,model1)\n",
        "    torch.save(model1, \"cifar10_models/state_dicts/iterative_50.pt\")\n",
        "print(\"Sparsity of model1\", calculate_sparsity(model1))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers to prune 21\n",
            "Iteration *********************************************** 1 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 1.577 | Acc: 42.432 (21216/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.582 | Acc: 80.070 (40035/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.418 | Acc: 85.514 (42757/50000)\n",
            "Current learning rate is: 0.1\n",
            "Iteration *********************************************** 2 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 0.394 | Acc: 86.538 (43269/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.315 | Acc: 89.184 (44592/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.271 | Acc: 90.556 (45278/50000)\n",
            "Current learning rate is: 0.1\n",
            "Iteration *********************************************** 3 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 0.261 | Acc: 90.938 (45469/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.228 | Acc: 92.062 (46031/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.205 | Acc: 92.906 (46453/50000)\n",
            "Current learning rate is: 0.1\n",
            "Iteration *********************************************** 4 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 0.195 | Acc: 93.120 (46560/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.176 | Acc: 93.874 (46937/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.163 | Acc: 94.284 (47142/50000)\n",
            "Current learning rate is: 0.1\n",
            "Iteration *********************************************** 5 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 0.162 | Acc: 94.250 (47125/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.143 | Acc: 94.960 (47480/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.143 | Acc: 94.996 (47498/50000)\n",
            "Current learning rate is: 0.1\n",
            "Total params:  11173972\n",
            "Zero params:  5535550\n",
            "Sparsity of model1 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qUKTqAUWlyb"
      },
      "source": [
        "Train and save the final model\n",
        "epochs = 51\n",
        "model1= model1.to(device)\n",
        "  for e in range(epochs):\n",
        "    if(e+1)%5==1:\n",
        "      print(f\"Epoch ======> {e+1}\")\n",
        "    train(e+1,model1)\n",
        "    torch.save(model1, \"cifar10_models/state_dicts/iterative_50.pt\")\n",
        "torch.save(model1, \"cifar10_models/state_dicts/iterative_50.pt\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ-DYnB8S5cB",
        "outputId": "7efa7fc4-a8a4-44ca-d192-1ca8adbc8fd2"
      },
      "source": [
        "# Build and save the iterative pruning model with 75 % sparsity ratio\n",
        "model2 = copy.deepcopy(my_model)\n",
        "\n",
        "parameters_to_prune =[]\n",
        "for module_name, module in model2.named_modules():\n",
        "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
        "            parameters_to_prune.append((module, \"weight\"))\n",
        "print(\"Layers to prune {}\".format((len(parameters_to_prune))))\n",
        "for i in range(5):\n",
        "  print(f\"Iteration *********************************************** {i+1} **************************************************\" )\n",
        "  prune.global_unstructured(\n",
        "  parameters_to_prune,\n",
        "  pruning_method=prune.L1Unstructured,\n",
        "  amount=0.24,\n",
        "  )\n",
        "  model2= model2.to(device)\n",
        "  for e in range(epochs):\n",
        "    if(e+1)%5==1:\n",
        "      print(f\"Epoch ======> {e+1}\")\n",
        "    train(e+1,model2)\n",
        "    torch.save(model2, \"cifar10_models/state_dicts/iterative_75.pt\")\n",
        "print(\"Sparsity of model2\", calculate_sparsity(model2))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers to prune 21\n",
            "Iteration *********************************************** 1 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 1.615 | Acc: 40.758 (20379/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.592 | Acc: 79.580 (39790/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.425 | Acc: 85.442 (42721/50000)\n",
            "Current learning rate is: 0.1\n",
            "Iteration *********************************************** 2 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 0.393 | Acc: 86.552 (43276/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.326 | Acc: 88.726 (44363/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.269 | Acc: 90.696 (45348/50000)\n",
            "Current learning rate is: 0.1\n",
            "Iteration *********************************************** 3 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 0.258 | Acc: 91.080 (45540/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.228 | Acc: 92.036 (46018/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.202 | Acc: 92.952 (46476/50000)\n",
            "Current learning rate is: 0.1\n",
            "Iteration *********************************************** 4 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 0.195 | Acc: 93.196 (46598/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.174 | Acc: 93.984 (46992/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.163 | Acc: 94.196 (47098/50000)\n",
            "Current learning rate is: 0.1\n",
            "Iteration *********************************************** 5 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 0.156 | Acc: 94.576 (47288/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.144 | Acc: 94.902 (47451/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.136 | Acc: 95.226 (47613/50000)\n",
            "Current learning rate is: 0.1\n",
            "Total params:  11173972\n",
            "Zero params:  8333602\n",
            "Sparsity of model2 75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeelNp75oHeW"
      },
      "source": [
        "# Train and save the final model\n",
        "epochs = 51\n",
        "model2= model2.to(device)\n",
        "  for e in range(epochs):\n",
        "    if(e+1)%5==1:\n",
        "      print(f\"Epoch ======> {e+1}\")\n",
        "    train(e+1,model2)\n",
        "    torch.save(model2, \"cifar10_models/state_dicts/iterative_75.pt\")\n",
        "torch.save(model2, \"cifar10_models/state_dicts/iterative_75.pt\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcEtS2YT2TZE",
        "outputId": "4141f873-9a40-42bc-975d-d23da5770ec6"
      },
      "source": [
        "# Build and save the iterative pruning model with 90 % sparsity ratio\n",
        "model3 = copy.deepcopy(my_model)\n",
        "parameters_to_prune =[]\n",
        "for module_name, module in model3.named_modules():\n",
        "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
        "            parameters_to_prune.append((module, \"weight\"))\n",
        "print(\"Layers to prune {}\".format((len(parameters_to_prune))))\n",
        "for i in range(5):\n",
        "  print(f\"Iteration *********************************************** {i+1} **************************************************\" )\n",
        "  prune.global_unstructured(\n",
        "  parameters_to_prune,\n",
        "  pruning_method=prune.L1Unstructured,\n",
        "  amount=0.36,\n",
        "  )\n",
        "  model3= model3.to(device)\n",
        "  for e in range(epochs):\n",
        "    if(e+1)%5==1:\n",
        "      print(f\"Epoch ======> {e+1}\")\n",
        "    train(e+1,model3)\n",
        "    torch.save(model3, \"cifar10_models/state_dicts/iterative_90.pt\")\n",
        "print(\"Sparsity of model3\", calculate_sparsity(model3))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers to prune 21\n",
            "Iteration *********************************************** 1 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 1.677 | Acc: 38.346 (19173/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.618 | Acc: 78.816 (39408/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.450 | Acc: 84.438 (42219/50000)\n",
            "Current learning rate is: 0.1\n",
            "Iteration *********************************************** 2 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 0.423 | Acc: 85.380 (42690/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.350 | Acc: 87.926 (43963/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.296 | Acc: 89.600 (44800/50000)\n",
            "Current learning rate is: 0.1\n",
            "Iteration *********************************************** 3 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 0.280 | Acc: 90.302 (45151/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.249 | Acc: 91.324 (45662/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.224 | Acc: 92.162 (46081/50000)\n",
            "Current learning rate is: 0.1\n",
            "Iteration *********************************************** 4 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 0.211 | Acc: 92.710 (46355/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.193 | Acc: 93.216 (46608/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.182 | Acc: 93.556 (46778/50000)\n",
            "Current learning rate is: 0.1\n",
            "Iteration *********************************************** 5 **************************************************\n",
            "Epoch ======> 1\n",
            "Training\n",
            "[390/391] Loss: 0.165 | Acc: 94.198 (47099/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 6\n",
            "Training\n",
            "[390/391] Loss: 0.159 | Acc: 94.480 (47240/50000)\n",
            "Current learning rate is: 0.1\n",
            "Epoch ======> 11\n",
            "Training\n",
            "[390/391] Loss: 0.148 | Acc: 94.784 (47392/50000)\n",
            "Current learning rate is: 0.1\n",
            "Total params:  11173972\n",
            "Zero params:  9965588\n",
            "Sparsity of model3 90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECe9sujx2v3_"
      },
      "source": [
        "#save the model\n",
        "epochs = 51\n",
        "model3= model3.to(device)\n",
        "  for e in range(epochs):\n",
        "    if(e+1)%5==1:\n",
        "      print(f\"Epoch ======> {e+1}\")\n",
        "    train(e+1,model3)\n",
        "    torch.save(model3, \"cifar10_models/state_dicts/iterative_90.pt\")\n",
        "torch.save(model3, \"cifar10_models/state_dicts/iterative_90.pt\")\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCDLO1UsEsHf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}